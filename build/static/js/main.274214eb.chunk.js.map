{"version":3,"sources":["components/NeuralNetworkFunctionApproximator.js","App.js","reportWebVitals.js","index.js"],"names":["NeuralNetworkVisualization","layers","weights","setWeights","useState","biases","setBiases","learningRate","setLearningRate","epoch","setEpoch","isTraining","setIsTraining","approximationData","setApproximationData","targetData","setTargetData","loss","setLoss","canvasRef","useRef","animationRef","networkRef","useEffect","initializeNetwork","newWeights","newBiases","i","length","layerWeights","layerBiases","j","neuronWeights","k","stddev","Math","sqrt","push","random","current","generateFunctionData","currentWeights","currentBiases","extendedDomain","PI","newTargetData","x","y","sin","yApprox","boundaryExtraSamples","ratio","newApproximationData","map","point","forward","input","activation","layer","bias","newActivation","sum","sigmoid","exp","backward","target","activations","preActivations","preActivation","outputError","o","deltas","currentDelta","newDelta","error","derivative","unshift","JSON","parse","stringify","change","reduce","err","stopTraining","cancelAnimationFrame","_approximationData$sa","canvas","ctx","getContext","clearRect","width","height","layerSpacing","minSpacingNeeded","neurons","neuronRadius","neuronSpacings","idealSpacing","max","layerHeights","sampleIndex","currentSample","currentOutput","layerNeurons","layerHeight","startY","prevLayerNeurons","prevLayerHeight","prevStartY","prevSpacing","currentSpacing","prevX","prevY","w","absW","abs","weightColor","min","weightWidth","beginPath","moveTo","lineTo","strokeStyle","lineWidth","stroke","midX","midY","fillStyle","textWidth","measureText","toFixed","fillRect","font","fillText","arc","fill","textAlign","textBaseline","inputText","outputText","targetText","outputWidth","targetWidth","maxWidth","React","createElement","className","type","step","value","onChange","e","parseFloat","disabled","onClick","startTraining","frameCount","train","trainEpoch","totalLoss","shuffledData","sort","slice","forEach","prev","requestAnimationFrame","resetNetwork","ref","ResponsiveContainer","LineChart","margin","top","right","left","bottom","data","CartesianGrid","strokeDasharray","XAxis","dataKey","label","position","offset","domain","tickFormatter","YAxis","angle","Tooltip","formatter","name","Legend","Line","dot","strokeWidth","isAnimationActive","App","NeuralNetworkFunctionApproximator","reportWebVitals","onPerfEntry","Function","__webpack_require__","then","bind","_ref","getCLS","getFID","getFCP","getLCP","getTTFB","ReactDOM","createRoot","document","getElementById","render","StrictMode"],"mappings":"+SA2nBeA,MAvnBoBA,KAEjC,MAAMC,EAAS,CAAC,EAAG,GAAI,GAAI,EAAG,EAAG,IAG1BC,EAASC,GAAcC,mBAAS,KAChCC,EAAQC,GAAaF,mBAAS,KAC9BG,EAAcC,GAAmBJ,mBAAS,MAC1CK,EAAOC,GAAYN,mBAAS,IAC5BO,EAAYC,GAAiBR,oBAAS,IACtCS,EAAmBC,GAAwBV,mBAAS,KACpDW,EAAYC,GAAiBZ,mBAAS,KACtCa,EAAMC,GAAWd,mBAAS,GAE3Be,EAAYC,iBAAO,MACnBC,EAAeD,iBAAO,MACtBE,EAAaF,iBAAO,CAAElB,QAAS,GAAIG,OAAQ,KAGjDkB,oBAAU,KACRC,KACC,IAGH,MAAMA,EAAoBA,KACxB,MAAMC,EAAa,GACbC,EAAY,GAElB,IAAK,IAAIC,EAAI,EAAGA,EAAI1B,EAAO2B,OAAS,EAAGD,IAAK,CAC1C,MAAME,EAAe,GACfC,EAAc,GAEpB,IAAK,IAAIC,EAAI,EAAGA,EAAI9B,EAAO0B,EAAI,GAAII,IAAK,CACtC,MAAMC,EAAgB,GACtB,IAAK,IAAIC,EAAI,EAAGA,EAAIhC,EAAO0B,GAAIM,IAAK,CAElC,MAAMC,EAASC,KAAKC,KAAK,GAAOnC,EAAO0B,GAAK1B,EAAO0B,EAAI,KACvDK,EAAcK,MAAsB,EAAhBF,KAAKG,SAAe,GAAKJ,GAE/CL,EAAaQ,KAAKL,GAClBF,EAAYO,KAA+B,KAAT,EAAhBF,KAAKG,SAAe,IAGxCb,EAAWY,KAAKR,GAChBH,EAAUW,KAAKP,GAIjB3B,EAAWsB,GACXnB,EAAUoB,GACVhB,EAAS,GACTQ,EAAQ,GAGRI,EAAWiB,QAAU,CACnBrC,QAASuB,EACTpB,OAAQqB,GAIVc,EAAqBf,EAAYC,IAI7Bc,EAAuBA,CAACC,EAAgBC,KAK5C,MAEMC,EAAiB,GAAMR,KAAKS,GAE5BC,EAAgB,GAGtB,IAAK,IAAIlB,EAAI,EAAGA,EAPO,GAOaA,IAAK,CACvC,MAAMmB,GAAKX,KAAKS,GAAKD,GAAmB,EAAIR,KAAKS,GAAK,EAAID,GAAkBhB,EAAC,GAGvEoB,EAAIZ,KAAKa,IAAIF,GAAK,GAAMX,KAAKa,IAAI,EAAIF,IAAMA,EAAIA,EAAI,GAEzDD,EAAcR,KAAK,CAAES,IAAGC,IAAGE,QAAS,IAItC,IAAK,IAAItB,EAAI,EAAGA,EAAIuB,GAA0BvB,IAAK,CACjD,MAAMwB,EAAQxB,EAAC,GACTmB,GAAKX,KAAKS,GAAKD,EAAiBQ,EAAQhB,KAAKS,GAAK,GAElDG,EAAIZ,KAAKa,IAAIF,GAAK,GAAMX,KAAKa,IAAI,EAAIF,IAAMA,EAAIA,EAAI,GACzDD,EAAcR,KAAK,CAAES,IAAGC,IAAGE,QAAS,IAItC,IAAK,IAAItB,EAAI,EAAGA,EAAIuB,GAA0BvB,IAAK,CACjD,MAAMwB,EAAQxB,EAAC,GACTmB,EAAc,GAAVX,KAAKS,GAAWO,GAAmB,GAAVhB,KAAKS,GAAWD,GAE7CI,EAAIZ,KAAKa,IAAIF,GAAK,GAAMX,KAAKa,IAAI,EAAIF,IAAMA,EAAIA,EAAI,GACzDD,EAAcR,KAAK,CAAES,IAAGC,IAAGE,QAAS,IAMtC,GAHAjC,EAAc6B,GAGVJ,GAAkBA,EAAeb,OAAS,EAAG,CAC/C,MAAMwB,EAAuBP,EAAcQ,IAAIC,IAC7C,MAAML,EAAUM,EAAQ,CAACD,EAAMR,GAAIL,EAAgBC,GAAe,GAClE,MAAO,CAAEI,EAAGQ,EAAMR,EAAGC,EAAGO,EAAMP,EAAGE,aAGnCnC,EAAqBsC,KAKnBG,EAAUA,CAACC,EAAOf,EAAgBC,KACtC,IAAIe,EAAa,IAAID,GACrB,MAAMtD,EAAUuC,GAAkBnB,EAAWiB,QAAQrC,QAC/CG,EAASqC,GAAiBpB,EAAWiB,QAAQlC,OAEnD,IAAK,IAAIsB,EAAI,EAAGA,EAAIzB,EAAQ0B,OAAQD,IAAK,CACvC,MAAM+B,EAAQxD,EAAQyB,GAChBgC,EAAOtD,EAAOsB,GACdiC,EAAgB,GAEtB,IAAK,IAAI7B,EAAI,EAAGA,EAAI2B,EAAM9B,OAAQG,IAAK,CACrC,MAAMC,EAAgB0B,EAAM3B,GAC5B,IAAI8B,EAAMF,EAAK5B,GAEf,IAAK,IAAIE,EAAI,EAAGA,EAAID,EAAcJ,OAAQK,IACxC4B,GAAO7B,EAAcC,GAAKwB,EAAWxB,GAIvC,GAAIN,EAAIzB,EAAQ0B,OAAS,EAAG,CAE1B,MAAMkC,EAAU,GAAK,EAAI3B,KAAK4B,KAAKF,IACnCD,EAAcvB,KAAKwB,EAAMC,QAEzBF,EAAcvB,KAAKwB,GAIvBJ,EAAa,IAAIG,GAGnB,OAAOH,GAIHO,EAAWA,CAACR,EAAOS,KACvB,MAAM/D,EAAUoB,EAAWiB,QAAQrC,QAC7BG,EAASiB,EAAWiB,QAAQlC,OAG5B6D,EAAc,CAACV,GACfW,EAAiB,GACvB,IAAIV,EAAa,IAAID,GAErB,IAAK,IAAI7B,EAAI,EAAGA,EAAIzB,EAAQ0B,OAAQD,IAAK,CACvC,MAAM+B,EAAQxD,EAAQyB,GAChBgC,EAAOtD,EAAOsB,GACdiC,EAAgB,GAChBQ,EAAgB,GAEtB,IAAK,IAAIrC,EAAI,EAAGA,EAAI2B,EAAM9B,OAAQG,IAAK,CACrC,MAAMC,EAAgB0B,EAAM3B,GAC5B,IAAI8B,EAAMF,EAAK5B,GAEf,IAAK,IAAIE,EAAI,EAAGA,EAAID,EAAcJ,OAAQK,IACxC4B,GAAO7B,EAAcC,GAAKwB,EAAWxB,GAMvC,GAHAmC,EAAc/B,KAAKwB,GAGflC,EAAIzB,EAAQ0B,OAAS,EAAG,CAC1B,MAAMkC,EAAU,GAAK,EAAI3B,KAAK4B,KAAKF,IACnCD,EAAcvB,KAAKwB,EAAMC,QAEzBF,EAAcvB,KAAKwB,GAIvBM,EAAe9B,KAAK+B,GACpBX,EAAa,IAAIG,GACjBM,EAAY7B,KAAKuB,GAInB,MACMS,EADSH,EAAYA,EAAYtC,OAAS,GACrByB,IAAI,CAACiB,EAAG3C,IAAM2C,EAAIL,EAAOtC,IAG9C4C,EAAS,CAACF,GAEhB,IAAK,IAAI1C,EAAIzB,EAAQ0B,OAAS,EAAGD,EAAI,EAAGA,IAAK,CAC3C,MAAM6C,EAAeD,EAAO,GACtBE,EAAW,GAEjB,IAAK,IAAI1C,EAAI,EAAGA,EAAI9B,EAAO0B,GAAII,IAAK,CAClC,IAAI2C,EAAQ,EAEZ,IAAK,IAAIzC,EAAI,EAAGA,EAAIuC,EAAa5C,OAAQK,IACvCyC,GAASF,EAAavC,GAAK/B,EAAQyB,GAAGM,GAAGF,GAI3C,MAAMe,EAAIqB,EAAexC,EAAE,GAAGI,GACxB+B,EAAU,GAAK,EAAI3B,KAAK4B,KAAKjB,IAC7B6B,EAAab,EAAUhB,EAAIgB,GAAW,EAAIA,GAEhDW,EAASpC,KAAKqC,EAAQC,GAGxBJ,EAAOK,QAAQH,GAIjB,MAAMhD,EAAaoD,KAAKC,MAAMD,KAAKE,UAAU7E,IACvCwB,EAAYmD,KAAKC,MAAMD,KAAKE,UAAU1E,IAG5C,IAAK,IAAIsB,EAAI,EAAGA,EAAIzB,EAAQ0B,OAAQD,IAClC,IAAK,IAAII,EAAI,EAAGA,EAAI7B,EAAQyB,GAAGC,OAAQG,IAAK,CAC1C,IAAK,IAAIE,EAAI,EAAGA,EAAI/B,EAAQyB,GAAGI,GAAGH,OAAQK,IAAK,CAC7C,MAAM+C,EAASzE,EAAegE,EAAO5C,GAAGI,GAAKmC,EAAYvC,GAAGM,GAC5DR,EAAWE,GAAGI,GAAGE,IAAM+C,EAGzBtD,EAAUC,GAAGI,IAAMxB,EAAegE,EAAO5C,GAAGI,GAchD,OATAT,EAAWiB,QAAU,CACnBrC,QAASuB,EACTpB,OAAQqB,GAGVvB,EAAW,IAAIsB,IACfnB,EAAU,IAAIoB,IAGP2C,EAAYY,OAAO,CAACpB,EAAKqB,IAAQrB,EAAMqB,EAAMA,EAAK,GAAKb,EAAYzC,QAiEtEuD,EAAeA,KACf9D,EAAakB,SACf6C,qBAAqB/D,EAAakB,SAEpC3B,GAAc,IAuLhB,OA7KAW,oBAAU,KAAM,IAAA8D,EACd,IAAKlE,EAAUoB,QAAS,OAExB,MAAM+C,EAASnE,EAAUoB,QACnBgD,EAAMD,EAAOE,WAAW,MAC9BD,EAAIE,UAAU,EAAG,EAAGH,EAAOI,MAAOJ,EAAOK,QAGzCL,EAAOI,MAAQ,IACfJ,EAAOK,OAAS,IAEhB,MACMD,EAAQJ,EAAOI,MAAQ,IACvBC,EAASL,EAAOK,OAAS,IAEzBC,EAAeF,GAASzF,EAAO2B,OAAS,GAIxCiE,EAAmB5F,EAAOoD,IAAIyC,GAE3BC,IAIHC,EAAiB/F,EAAOoD,IAAI,CAACyC,EAASnE,KAC1C,MAAMsE,EAAeN,EAAUG,EAE/B,OAAO3D,KAAK+D,IAAIL,EAAiBlE,GAAIsE,KAIjCE,EAAelG,EAAOoD,IAAI,CAACyC,EAASnE,KAAOmE,EAAU,GAAKE,EAAerE,IAGzEyE,EAAc3F,EAAQM,EAAWa,OACjCyE,EAAgBtF,EAAWqF,IAAgB,CAAEtD,EAAG,EAAGC,EAAG,GAGtDuD,GAA8C,QAA9BjB,EAAAxE,EAAkBuF,UAAY,IAAAf,OAAA,EAA9BA,EAAgCpC,UAAW,EAGjE,IAAK,IAAItB,EAAI,EAAGA,EAAI1B,EAAO2B,OAAQD,IAAK,CACtC,MAAM4E,EAAetG,EAAO0B,GACtB6E,EAAcL,EAAaxE,GAC3B8E,EAlCO,IAkCYd,EAASa,GAAe,EAGjD,GAAI7E,EAAI,EAAG,CACT,MAAM+E,EAAmBzG,EAAO0B,EAAI,GAC9BgF,EAAkBR,EAAaxE,EAAI,GACnCiF,EAxCK,IAwCkBjB,EAASgB,GAAmB,EACnDE,EAAcb,EAAerE,EAAE,GAC/BmF,EAAiBd,EAAerE,GAEtC,IAAK,IAAII,EAAI,EAAGA,EAAIwE,EAAcxE,IAAK,CACrC,MAAMe,EA7CG,GA6CUnB,EAAIiE,EACjB7C,EAAI0D,EAAS1E,EAAI+E,EAEvB,IAAK,IAAI7E,EAAI,EAAGA,EAAIyE,EAAkBzE,IAAK,CACzC,MAAM8E,EAjDC,IAiDiBpF,EAAI,GAAKiE,EAC3BoB,EAAQJ,EAAa3E,EAAI4E,EAG/B,GAAIvF,EAAWiB,QAAQrC,QAAQ0B,OAAS,GAAKD,EAAI,EAAIL,EAAWiB,QAAQrC,QAAQ0B,OAAQ,CACtF,MAAMqF,EAAI3F,EAAWiB,QAAQrC,QAAQyB,EAAI,GAAGI,IAAKT,EAAWiB,QAAQrC,QAAQyB,EAAI,GAAGI,GAAGE,IAAU,EAC1FiF,EAAO/E,KAAKgF,IAAIF,GAGtB,GAAIC,EAAO,IAAM,CAEf,MAAME,EAAcH,EAAI,qBAAuB9E,KAAKkF,IAAIH,EAAM,yBAA2B/E,KAAKkF,IAAIH,EAAM,MAGlGI,EAAc,GAAM,EAAInF,KAAKkF,IAAIH,EAAM,GAU7C,GARA3B,EAAIgC,YACJhC,EAAIiC,OAAOT,EA7DF,GA6DwBC,GACjCzB,EAAIkC,OAAO3E,EA9DF,GA8DoBC,GAC7BwC,EAAImC,YAAcN,EAClB7B,EAAIoC,UAAYL,EAChB/B,EAAIqC,SAGAV,EAAO,GAAK,CAEd,MAAMW,GAAQd,EAtEP,GAsE8BjE,EAtE9B,IAsEkD,EACnDgF,GAAQd,EAAQjE,GAAK,EAG3BwC,EAAIwC,UAAY,2BAChB,MAAMC,EAAYzC,EAAI0C,YAAYhB,EAAEiB,QAAQ,IAAIxC,MAChDH,EAAI4C,SAASN,EAAOG,EAAU,EAAI,EAAGF,EAAO,EAAGE,EAAY,EAAG,IAE9DzC,EAAIwC,UAAY,UAChBxC,EAAI6C,KAAO,YACX7C,EAAI8C,SAASpB,EAAEiB,QAAQ,GAAIL,EAAMC,QAS7C,IAAK,IAAI/F,EAAI,EAAGA,EAAIwE,EAAcxE,IAAK,CACrC,MAAMe,EA/FK,GA+FQnB,EAAIiE,EACjB7C,EAAI0D,EAAS1E,EAAIiE,EAAerE,GAmBtC,GAhBA4D,EAAIgC,YACJhC,EAAI+C,IAAIxF,EAAGC,EA/FM,GA+FW,EAAG,EAAIZ,KAAKS,IACxC2C,EAAIwC,UAAkB,IAANpG,EAAU,UAAYA,IAAM1B,EAAO2B,OAAS,EAAI,UAAY,UAC5E2D,EAAIgD,OACJhD,EAAImC,YAAc,UAClBnC,EAAIoC,UAAY,EAChBpC,EAAIqC,SAGJrC,EAAIwC,UAAY,UAChBxC,EAAI6C,KAAO,YACX7C,EAAIiD,UAAY,SAChBjD,EAAIkD,aAAe,SACnBlD,EAAI8C,YAAY1G,EAAE,KAAKI,EAAE,IAAKe,EAAGC,GAGvB,IAANpB,EAAS,CACX4D,EAAIwC,UAAY,UAChBxC,EAAI6C,KAAO,kBACX7C,EAAIiD,UAAY,QAGhB,MAAME,cAAwBrC,EAAcvD,EAAEoF,QAAQ,KAChDF,EAAYzC,EAAI0C,YAAYS,GAAWhD,MAC7CH,EAAIwC,UAAY,2BAChBxC,EAAI4C,SAASrF,EAvHE,GAuHiB,EAAIkF,EAAWjF,EAAI,EAAGiF,EAAY,EAAG,IAErEzC,EAAIwC,UAAY,UAChBxC,EAAI8C,SAASK,EAAW5F,EA1HT,GA0H4B,EAAGC,QACzC,GAAIpB,IAAM1B,EAAO2B,OAAS,EAAG,CAElC,MAAM+G,aAAwBrC,EAAc4B,QAAQ,KAC9CU,aAAwBvC,EAActD,EAAEmF,QAAQ,KAEhDW,EAActD,EAAI0C,YAAYU,GAAYjD,MAC1CoD,EAAcvD,EAAI0C,YAAYW,GAAYlD,MAC1CqD,EAAW5G,KAAK+D,IAAI2C,EAAaC,GAEvCvD,EAAIwC,UAAY,2BAChBxC,EAAI4C,SAASrF,EArIE,GAqIiB,EAAGC,EAAI,GAAIgG,EAAW,EAAG,IAEzDxD,EAAIwC,UAAY,UAChBxC,EAAI6C,KAAO,kBACX7C,EAAIiD,UAAY,OAChBjD,EAAI8C,SAASM,EAAY7F,EA1IV,GA0I6B,GAAIC,EAAI,GAEpDwC,EAAIwC,UAAY,UAChBxC,EAAI8C,SAASO,EAAY9F,EA7IV,GA6I6B,GAAIC,EAAI,QAIzD,CAAC7C,EAASO,EAAOM,EAAYF,IAGhCU,oBAAU,IACD,KACDF,EAAakB,SACf6C,qBAAqB/D,EAAakB,UAGrC,IAIDyG,IAAAC,cAAA,OAAKC,UAAU,uBACbF,IAAAC,cAAA,MAAIC,UAAU,sCAAqC,4DAEnDF,IAAAC,cAAA,OAAKC,UAAU,8CACbF,IAAAC,cAAA,OAAKC,UAAU,0BACbF,IAAAC,cAAA,MAAIC,UAAU,8BAA6B,iBAE3CF,IAAAC,cAAA,OAAKC,UAAU,QACbF,IAAAC,cAAA,KAAGC,UAAU,gBAAe,kEAC5BF,IAAAC,cAAA,SAAOC,UAAU,kCAAiC,kBAAgB3I,EAAa2H,QAAQ,IACvFc,IAAAC,cAAA,SACEE,KAAK,QACL9B,IAAI,QACJnB,IAAI,MACJkD,KAAK,QACLC,MAAO9I,EACP+I,SAAUC,GAAK/I,EAAgBgJ,WAAWD,EAAEtF,OAAOoF,QACnDH,UAAU,SACVO,SAAU9I,KAIdqI,IAAAC,cAAA,OAAKC,UAAU,kBACbF,IAAAC,cAAA,UACES,QAAS/I,EAAawE,EA9OZwE,KACpB,GAAIhJ,EAAY,OAEhBC,GAAc,GACd,IAAIgJ,EAAa,EAEjB,MAAMC,EAAQA,OACZD,EAGiB,IAAM,IA7CRE,MACjB,IAAIC,EAAY,EAGhB,MAAMC,EAAe,IAAIjJ,GAAYkJ,KAAK,IAAM9H,KAAKG,SAAW,IAIhE,IAAK,IAAIX,EAAI,EAAGA,EAAIqI,EAAapI,OAAQD,GADvB,GAEFqI,EAAaE,MAAMvI,EAAGQ,KAAKkF,IAAI1F,EAF7B,GAE4CqI,EAAapI,SAEnEuI,QAAQ7G,IACZ,MAAMoB,EAAQV,EAAS,CAACV,EAAMR,GAAI,CAACQ,EAAMP,IACzCgH,GAAarF,IAIjBqF,GAAaC,EAAapI,OAG1B,MAAMwB,EAAuBrC,EAAWsC,IAAIC,IAC1C,MAAML,EAAUM,EAAQ,CAACD,EAAMR,GAAIxB,EAAWiB,QAAQrC,QAASoB,EAAWiB,QAAQlC,QAAQ,GAC1F,MAAO,CAAEyC,EAAGQ,EAAMR,EAAGC,EAAGO,EAAMP,EAAGE,aASnC,OALAnC,EAAqB,IAAIsC,IACzBlC,EAAQ6I,GACRrJ,EAAS0J,GAAQA,EAAO,GAGhBL,EAAY,MAAUtJ,GAAS,KAAQA,GAAS,KAelCqJ,IAEDrJ,GAAS,KACxBG,GAAc,GAKlBS,EAAakB,QAAU8H,sBAAsBR,IAG/CxI,EAAakB,QAAU8H,sBAAsBR,IAyNnCX,+BAAgCvI,EAAa,8BAAgC,4DAE5EA,EAAa,gBAAkB,kBAGlCqI,IAAAC,cAAA,UACES,QAnNSY,KACnBnF,IACA3D,KAkNU0H,UAAU,yEACVO,SAAU9I,GACX,kBAKHqI,IAAAC,cAAA,OAAKC,UAAU,QACbF,IAAAC,cAAA,KAAGC,UAAU,WAAU,kBAAeF,IAAAC,cAAA,QAAMC,UAAU,iBAAiBzI,IACvEuI,IAAAC,cAAA,KAAGC,UAAU,WAAU,iBAAcF,IAAAC,cAAA,QAAMC,UAAU,iBAAiBjI,EAAKiH,QAAQ,OAIvFc,IAAAC,cAAA,OAAKC,UAAU,0BACbF,IAAAC,cAAA,MAAIC,UAAU,8BAA6B,mCAC3CF,IAAAC,cAAA,OAAKC,UAAU,2BACbF,IAAAC,cAAA,UAAQsB,IAAKpJ,EAAWuE,MAAM,MAAMC,OAAO,MAAMuD,UAAU,iBAE7DF,IAAAC,cAAA,KAAGC,UAAU,8BAA6B,gHAI9CF,IAAAC,cAAA,OAAKC,UAAU,0BACbF,IAAAC,cAAA,MAAIC,UAAU,8BAA6B,0BAC3CF,IAAAC,cAAA,OAAKC,UAAU,2BACbF,IAAAC,cAACuB,IAAmB,CAAC9E,MAAM,OAAOC,OAAQ,KACxCqD,IAAAC,cAACwB,IAAS,CACRC,OAAQ,CAAEC,IAAK,GAAIC,MAAO,GAAIC,KAAM,GAAIC,OAAQ,IAChDC,KAAMlK,GAENmI,IAAAC,cAAC+B,IAAa,CAACC,gBAAgB,QAC/BjC,IAAAC,cAACiC,IAAK,CACJC,QAAQ,IACRC,MAAO,CAAE/B,MAAO,IAAKgC,SAAU,SAAUC,OAAQ,GACjDC,OAAQ,CAAY,KAAVpJ,KAAKS,GAAoB,IAAVT,KAAKS,IAC9B4I,cAAgBnC,GAAUA,EAAMnB,QAAQ,KAE1Cc,IAAAC,cAACwC,IAAK,CACJL,MAAO,CAAE/B,MAAO,IAAKqC,OAAQ,GAAIL,SAAU,OAAQC,QAAS,GAC5DC,OAAQ,EAAE,EAAG,KAEfvC,IAAAC,cAAC0C,IAAO,CAACC,UAAWA,CAACvC,EAAOwC,IAAS,CAACxC,EAAMnB,QAAQ,GAAI2D,KACxD7C,IAAAC,cAAC6C,IAAM,MACP9C,IAAAC,cAAC8C,IAAI,CACH5C,KAAK,WACLgC,QAAQ,IACRU,KAAK,kBACLjE,OAAO,UACPoE,KAAK,EACLC,YAAa,IAEfjD,IAAAC,cAAC8C,IAAI,CACH5C,KAAK,WACLgC,QAAQ,UACRU,KAAK,yBACLjE,OAAO,UACPoE,KAAK,EACLC,YAAa,EACbC,mBAAmB,OAK3BlD,IAAAC,cAAA,OAAKC,UAAU,gBACbF,IAAAC,cAAA,SAAGD,IAAAC,cAAA,QAAMC,UAAU,4CAAiD,oDACpEF,IAAAC,cAAA,SAAGD,IAAAC,cAAA,QAAMC,UAAU,2CAAgD,qDAIvEF,IAAAC,cAAA,OAAKC,UAAU,+BACbF,IAAAC,cAAA,MAAIC,UAAU,8BAA6B,qCAC3CF,IAAAC,cAAA,OAAKC,UAAU,yCACbF,IAAAC,cAAA,WACED,IAAAC,cAAA,MAAIC,UAAU,oBAAmB,4BACjCF,IAAAC,cAAA,KAAGC,UAAU,gBAAe,iCAC5BF,IAAAC,cAAA,MAAIC,UAAU,8CACZF,IAAAC,cAAA,UAAI,2DACJD,IAAAC,cAAA,UAAI,kDACJD,IAAAC,cAAA,UAAI,gDACJD,IAAAC,cAAA,UAAI,oDAGRD,IAAAC,cAAA,WACED,IAAAC,cAAA,MAAIC,UAAU,oBAAmB,2BACjCF,IAAAC,cAAA,KAAGC,UAAU,WAAU,uEAGvBF,IAAAC,cAAA,MAAIC,UAAU,2CACZF,IAAAC,cAAA,UAAI,wDACJD,IAAAC,cAAA,UAAI,gDACJD,IAAAC,cAAA,UAAI,0DACJD,IAAAC,cAAA,UAAI,0HC9lBHkD,MAhBf,WACE,OACEnD,IAAAC,cAAA,OAAKC,UAAU,OACbF,IAAAC,cAAA,UAAQC,UAAU,cAChBF,IAAAC,cAAA,UAAI,0CAEND,IAAAC,cAAA,QAAMC,UAAU,YACdF,IAAAC,cAACmD,EAAiC,OAEpCpD,IAAAC,cAAA,UAAQC,UAAU,cAChBF,IAAAC,cAAA,SAAG,yBCFIoD,MAZSC,IAClBA,GAAeA,aAAuBC,UACxCC,EAAAjD,EAAA,GAAAkD,KAAAD,EAAAE,KAAA,WAAqBD,KAAKE,IAAiD,IAAhDC,OAAEA,EAAMC,OAAEA,EAAMC,OAAEA,EAAMC,OAAEA,EAAMC,QAAEA,GAASL,EACpEC,EAAON,GACPO,EAAOP,GACPQ,EAAOR,GACPS,EAAOT,GACPU,EAAQV,MCDDW,IAASC,WAAWC,SAASC,eAAe,SACpDC,OACHrE,IAAAC,cAACD,IAAMsE,WAAU,KACftE,IAAAC,cAACkD,EAAG,QAORE","file":"static/js/main.274214eb.chunk.js","sourcesContent":["import React, { useState, useEffect, useRef } from 'react';\nimport { LineChart, Line, XAxis, YAxis, CartesianGrid, Tooltip, Legend, ResponsiveContainer } from 'recharts';\n\n// Neural Network Visualization Component\nconst NeuralNetworkVisualization = () => {\n  // Fixed network structure: 1 input, four hidden layers with architecture adjustments, 1 output\n  const layers = [1, 12, 10, 8, 6, 1];\n  \n  // State variables\n  const [weights, setWeights] = useState([]); // Network weights\n  const [biases, setBiases] = useState([]); // Network biases\n  const [learningRate, setLearningRate] = useState(0.05); // Learning rate\n  const [epoch, setEpoch] = useState(0); // Current training epoch\n  const [isTraining, setIsTraining] = useState(false); // Training status\n  const [approximationData, setApproximationData] = useState([]); // Approximation function data\n  const [targetData, setTargetData] = useState([]); // Target function data\n  const [loss, setLoss] = useState(1.0); // Current loss\n\n  const canvasRef = useRef(null);\n  const animationRef = useRef(null);\n  const networkRef = useRef({ weights: [], biases: [] });\n\n  // Initialize network\n  useEffect(() => {\n    initializeNetwork();\n  }, []);\n\n  // Initialize network weights and biases\n  const initializeNetwork = () => {\n    const newWeights = [];\n    const newBiases = [];\n    \n    for (let i = 0; i < layers.length - 1; i++) {\n      const layerWeights = [];\n      const layerBiases = [];\n      \n      for (let j = 0; j < layers[i + 1]; j++) {\n        const neuronWeights = [];\n        for (let k = 0; k < layers[i]; k++) {\n          // Initialize weights (using Xavier initialization)\n          const stddev = Math.sqrt(1.0 / (layers[i] + layers[i + 1]));\n          neuronWeights.push((Math.random() * 2 - 1) * stddev);\n        }\n        layerWeights.push(neuronWeights);\n        layerBiases.push((Math.random() * 2 - 1) * 0.05);\n      }\n      \n      newWeights.push(layerWeights);\n      newBiases.push(layerBiases);\n    }\n    \n    // Update component state\n    setWeights(newWeights);\n    setBiases(newBiases);\n    setEpoch(0);\n    setLoss(1.0);\n    \n    // Also update reference to ensure always using latest weights\n    networkRef.current = {\n      weights: newWeights,\n      biases: newBiases\n    };\n    \n    // Generate initial data\n    generateFunctionData(newWeights, newBiases);\n  };\n\n  // Generate target function data (more complex function with extended domain and higher boundary sampling)\n  const generateFunctionData = (currentWeights, currentBiases) => {\n    // Create two sets of samples:\n    // 1. Regular samples across the domain\n    // 2. Extra samples concentrated at boundaries\n    \n    const regularSamples = 40;\n    const boundaryExtraSamples = 20; // Extra samples focused on boundaries\n    const extendedDomain = 0.1 * Math.PI; // Extend domain by 10% of π\n    \n    const newTargetData = [];\n    \n    // Regular samples across the domain\n    for (let i = 0; i < regularSamples; i++) {\n      const x = -Math.PI - extendedDomain + ((2 * Math.PI + 2 * extendedDomain) * i) / (regularSamples - 1);\n      \n      // Complex target function: sin(x) + 0.5*sin(3x) * x^2/5\n      const y = Math.sin(x) + 0.5 * Math.sin(3 * x) * (x * x / 5);\n      \n      newTargetData.push({ x, y, yApprox: 0 });\n    }\n    \n    // Extra samples near left boundary\n    for (let i = 0; i < boundaryExtraSamples / 2; i++) {\n      const ratio = i / (boundaryExtraSamples / 2);\n      const x = -Math.PI - extendedDomain + ratio * Math.PI * 0.4; // Focus on first 40% of left side\n      \n      const y = Math.sin(x) + 0.5 * Math.sin(3 * x) * (x * x / 5);\n      newTargetData.push({ x, y, yApprox: 0 });\n    }\n    \n    // Extra samples near right boundary\n    for (let i = 0; i < boundaryExtraSamples / 2; i++) {\n      const ratio = i / (boundaryExtraSamples / 2);\n      const x = Math.PI * 0.6 + ratio * (Math.PI * 0.4 + extendedDomain); // Focus on last 40% of right side\n      \n      const y = Math.sin(x) + 0.5 * Math.sin(3 * x) * (x * x / 5);\n      newTargetData.push({ x, y, yApprox: 0 });\n    }\n    \n    setTargetData(newTargetData);\n    \n    // Calculate initial approximation function\n    if (currentWeights && currentWeights.length > 0) {\n      const newApproximationData = newTargetData.map(point => {\n        const yApprox = forward([point.x], currentWeights, currentBiases)[0];\n        return { x: point.x, y: point.y, yApprox };\n      });\n      \n      setApproximationData(newApproximationData);\n    }\n  };\n\n  // Forward propagation with SiLU (Swish) activation\n  const forward = (input, currentWeights, currentBiases) => {\n    let activation = [...input];\n    const weights = currentWeights || networkRef.current.weights;\n    const biases = currentBiases || networkRef.current.biases;\n    \n    for (let i = 0; i < weights.length; i++) {\n      const layer = weights[i];\n      const bias = biases[i];\n      const newActivation = [];\n      \n      for (let j = 0; j < layer.length; j++) {\n        const neuronWeights = layer[j];\n        let sum = bias[j];\n        \n        for (let k = 0; k < neuronWeights.length; k++) {\n          sum += neuronWeights[k] * activation[k];\n        }\n        \n        // Use SiLU/Swish activation function (x * sigmoid(x)) for hidden layers\n        if (i < weights.length - 1) {\n          // SiLU/Swish: x * sigmoid(x)\n          const sigmoid = 1 / (1 + Math.exp(-sum));\n          newActivation.push(sum * sigmoid);\n        } else {\n          newActivation.push(sum); // No activation function for output layer\n        }\n      }\n      \n      activation = [...newActivation];\n    }\n    \n    return activation;\n  };\n\n  // Backward propagation with SiLU derivative\n  const backward = (input, target) => {\n    const weights = networkRef.current.weights;\n    const biases = networkRef.current.biases;\n    \n    // Forward pass and save activations and pre-activations for each layer\n    const activations = [input]; // Outputs after activation\n    const preActivations = []; // Inputs before activation\n    let activation = [...input];\n    \n    for (let i = 0; i < weights.length; i++) {\n      const layer = weights[i];\n      const bias = biases[i];\n      const newActivation = [];\n      const preActivation = [];\n      \n      for (let j = 0; j < layer.length; j++) {\n        const neuronWeights = layer[j];\n        let sum = bias[j];\n        \n        for (let k = 0; k < neuronWeights.length; k++) {\n          sum += neuronWeights[k] * activation[k];\n        }\n        \n        preActivation.push(sum);\n        \n        // Use SiLU activation for hidden layers\n        if (i < weights.length - 1) {\n          const sigmoid = 1 / (1 + Math.exp(-sum));\n          newActivation.push(sum * sigmoid);\n        } else {\n          newActivation.push(sum);\n        }\n      }\n      \n      preActivations.push(preActivation);\n      activation = [...newActivation];\n      activations.push(newActivation);\n    }\n    \n    // Calculate output layer error\n    const output = activations[activations.length - 1];\n    const outputError = output.map((o, i) => o - target[i]);\n    \n    // Backpropagate error\n    const deltas = [outputError];\n    \n    for (let i = weights.length - 1; i > 0; i--) {\n      const currentDelta = deltas[0];\n      const newDelta = [];\n      \n      for (let j = 0; j < layers[i]; j++) {\n        let error = 0;\n        \n        for (let k = 0; k < currentDelta.length; k++) {\n          error += currentDelta[k] * weights[i][k][j];\n        }\n        \n        // SiLU/Swish derivative: sigmoid(x) + x*sigmoid(x)*(1-sigmoid(x))\n        const x = preActivations[i-1][j];\n        const sigmoid = 1 / (1 + Math.exp(-x));\n        const derivative = sigmoid + x * sigmoid * (1 - sigmoid);\n        \n        newDelta.push(error * derivative);\n      }\n      \n      deltas.unshift(newDelta);\n    }\n    \n    // Create deep copies of weights and biases\n    const newWeights = JSON.parse(JSON.stringify(weights));\n    const newBiases = JSON.parse(JSON.stringify(biases));\n    \n    // Update weights and biases\n    for (let i = 0; i < weights.length; i++) {\n      for (let j = 0; j < weights[i].length; j++) {\n        for (let k = 0; k < weights[i][j].length; k++) {\n          const change = learningRate * deltas[i][j] * activations[i][k];\n          newWeights[i][j][k] -= change;\n        }\n        \n        newBiases[i][j] -= learningRate * deltas[i][j];\n      }\n    }\n    \n    // Update reference and state\n    networkRef.current = {\n      weights: newWeights,\n      biases: newBiases\n    };\n    \n    setWeights([...newWeights]);\n    setBiases([...newBiases]);\n    \n    // Calculate mean squared error\n    return outputError.reduce((sum, err) => sum + err * err, 0) / outputError.length;\n  };\n\n  // Train one epoch\n  const trainEpoch = () => {\n    let totalLoss = 0;\n    \n    // Randomly shuffle training data\n    const shuffledData = [...targetData].sort(() => Math.random() - 0.5);\n    \n    // Mini-batch gradient descent\n    const batchSize = 10;\n    for (let i = 0; i < shuffledData.length; i += batchSize) {\n      const batch = shuffledData.slice(i, Math.min(i + batchSize, shuffledData.length));\n      \n      batch.forEach(point => {\n        const error = backward([point.x], [point.y]);\n        totalLoss += error;\n      });\n    }\n    \n    totalLoss /= shuffledData.length;\n    \n    // Update approximation function data\n    const newApproximationData = targetData.map(point => {\n      const yApprox = forward([point.x], networkRef.current.weights, networkRef.current.biases)[0];\n      return { x: point.x, y: point.y, yApprox };\n    });\n    \n    // Update UI state\n    setApproximationData([...newApproximationData]);\n    setLoss(totalLoss);\n    setEpoch(prev => prev + 1);\n    \n    // For more complex functions, allow more training epochs before stopping\n    return (totalLoss < 0.0001 && epoch >= 300) || epoch >= 2000;\n  };\n\n  // Start training\n  const startTraining = () => {\n    if (isTraining) return;\n    \n    setIsTraining(true);\n    let frameCount = 0;\n    \n    const train = () => {\n      frameCount++;\n      \n      // Execute training every few frames to avoid UI blocking\n      if (frameCount % 3 === 0) {\n        const converged = trainEpoch();\n        \n        if (converged || epoch >= 1000) {\n          setIsTraining(false);\n          return;\n        }\n      }\n      \n      animationRef.current = requestAnimationFrame(train);\n    };\n    \n    animationRef.current = requestAnimationFrame(train);\n  };\n\n  // Stop training\n  const stopTraining = () => {\n    if (animationRef.current) {\n      cancelAnimationFrame(animationRef.current);\n    }\n    setIsTraining(false);\n  };\n\n  // Reset network\n  const resetNetwork = () => {\n    stopTraining();\n    initializeNetwork();\n  };\n\n  // Draw neural network\n  useEffect(() => {\n    if (!canvasRef.current) return;\n    \n    const canvas = canvasRef.current;\n    const ctx = canvas.getContext('2d');\n    ctx.clearRect(0, 0, canvas.width, canvas.height);\n    \n    // Adjust canvas size for better visibility\n    canvas.width = 700; // Increase canvas width\n    canvas.height = 500; // Increase canvas height\n    \n    const margin = 70; // Increased margin\n    const width = canvas.width - 2 * margin;\n    const height = canvas.height - 2 * margin;\n    \n    const layerSpacing = width / (layers.length - 1);\n    const neuronRadius = 12; // Reduced neuron radius\n    \n    // Calculate minimum spacing needed for each layer\n    const minSpacingNeeded = layers.map(neurons => {\n      // At least 2.5 * neuron diameter between centers to avoid overlap\n      return neuronRadius * 5;\n    });\n    \n    // Calculate actual spacing based on available height and neurons\n    const neuronSpacings = layers.map((neurons, i) => {\n      const idealSpacing = height / (neurons);\n      // Use at least minimum spacing or ideal spacing, whichever is larger\n      return Math.max(minSpacingNeeded[i], idealSpacing);\n    });\n    \n    // Calculate layer heights\n    const layerHeights = layers.map((neurons, i) => (neurons - 1) * neuronSpacings[i]);\n    \n    // Select current data sample for display\n    const sampleIndex = epoch % targetData.length;\n    const currentSample = targetData[sampleIndex] || { x: 0, y: 0 };\n    \n    // Calculate network output for current sample\n    const currentOutput = approximationData[sampleIndex]?.yApprox || 0;\n    \n    // Draw neurons and connections\n    for (let i = 0; i < layers.length; i++) {\n      const layerNeurons = layers[i];\n      const layerHeight = layerHeights[i];\n      const startY = margin + (height - layerHeight) / 2;\n      \n      // Draw connections first (so neurons are drawn on top)\n      if (i > 0) {\n        const prevLayerNeurons = layers[i - 1];\n        const prevLayerHeight = layerHeights[i - 1];\n        const prevStartY = margin + (height - prevLayerHeight) / 2;\n        const prevSpacing = neuronSpacings[i-1];\n        const currentSpacing = neuronSpacings[i];\n        \n        for (let j = 0; j < layerNeurons; j++) {\n          const x = margin + i * layerSpacing;\n          const y = startY + j * currentSpacing;\n          \n          for (let k = 0; k < prevLayerNeurons; k++) {\n            const prevX = margin + (i - 1) * layerSpacing;\n            const prevY = prevStartY + k * prevSpacing;\n            \n            // Set connection color and width based on weight\n            if (networkRef.current.weights.length > 0 && i - 1 < networkRef.current.weights.length) {\n              const w = networkRef.current.weights[i - 1][j] ? networkRef.current.weights[i - 1][j][k] || 0 : 0;\n              const absW = Math.abs(w);\n              \n              // Only draw connections with significant weights\n              if (absW > 0.05) {\n                // Weight color: green for positive, red for negative\n                const weightColor = w > 0 ? `rgba(0, 128, 0, ${Math.min(absW, 1)})` : `rgba(255, 0, 0, ${Math.min(absW, 1)})`;\n                \n                // Weight width: thicker for larger absolute values\n                const weightWidth = 0.5 + 2 * Math.min(absW, 1);\n                \n                ctx.beginPath();\n                ctx.moveTo(prevX + neuronRadius, prevY);\n                ctx.lineTo(x - neuronRadius, y);\n                ctx.strokeStyle = weightColor;\n                ctx.lineWidth = weightWidth;\n                ctx.stroke();\n                \n                // Only show weight values for significant weights\n                if (absW > 0.3) {\n                  // Show weight value\n                  const midX = (prevX + neuronRadius + x - neuronRadius) / 2;\n                  const midY = (prevY + y) / 2;\n                  \n                  // White background for text clarity\n                  ctx.fillStyle = 'rgba(255, 255, 255, 0.7)';\n                  const textWidth = ctx.measureText(w.toFixed(2)).width;\n                  ctx.fillRect(midX - textWidth/2 - 2, midY - 7, textWidth + 4, 14);\n                  \n                  ctx.fillStyle = '#000000';\n                  ctx.font = '9px Arial';\n                  ctx.fillText(w.toFixed(2), midX, midY);\n                }\n              }\n            }\n          }\n        }\n      }\n      \n      // Now draw neurons on top of connections\n      for (let j = 0; j < layerNeurons; j++) {\n        const x = margin + i * layerSpacing;\n        const y = startY + j * neuronSpacings[i];\n        \n        // Draw neuron\n        ctx.beginPath();\n        ctx.arc(x, y, neuronRadius, 0, 2 * Math.PI);\n        ctx.fillStyle = i === 0 ? '#88CCEE' : i === layers.length - 1 ? '#DDCC77' : '#44AA99';\n        ctx.fill();\n        ctx.strokeStyle = '#000000';\n        ctx.lineWidth = 1;\n        ctx.stroke();\n        \n        // Show neuron number\n        ctx.fillStyle = '#000000';\n        ctx.font = '9px Arial';\n        ctx.textAlign = 'center';\n        ctx.textBaseline = 'middle';\n        ctx.fillText(`${i+1}-${j+1}`, x, y);\n        \n        // Show input/output values - fixed position and display\n        if (i === 0) { // Input layer\n          ctx.fillStyle = '#000000';\n          ctx.font = 'bold 10px Arial';\n          ctx.textAlign = 'right';\n          \n          // Add background for better text clarity\n          const inputText = `Input x: ${currentSample.x.toFixed(2)}`;\n          const textWidth = ctx.measureText(inputText).width;\n          ctx.fillStyle = 'rgba(255, 255, 255, 0.8)';\n          ctx.fillRect(x - neuronRadius - 8 - textWidth, y - 7, textWidth + 4, 14);\n          \n          ctx.fillStyle = '#000000';\n          ctx.fillText(inputText, x - neuronRadius - 8, y);\n        } else if (i === layers.length - 1) { // Output layer\n          // Add background box for output\n          const outputText = `Output: ${currentOutput.toFixed(2)}`;\n          const targetText = `Target: ${currentSample.y.toFixed(2)}`;\n          \n          const outputWidth = ctx.measureText(outputText).width;\n          const targetWidth = ctx.measureText(targetText).width;\n          const maxWidth = Math.max(outputWidth, targetWidth);\n          \n          ctx.fillStyle = 'rgba(255, 255, 255, 0.8)';\n          ctx.fillRect(x + neuronRadius + 8, y - 15, maxWidth + 8, 30);\n          \n          ctx.fillStyle = '#0000AA';\n          ctx.font = 'bold 10px Arial';\n          ctx.textAlign = 'left';\n          ctx.fillText(outputText, x + neuronRadius + 12, y - 5);\n          \n          ctx.fillStyle = '#AA0000';\n          ctx.fillText(targetText, x + neuronRadius + 12, y + 10);\n        }\n      }\n    }\n  }, [weights, epoch, targetData, approximationData]);\n\n  // Cleanup on component unmount\n  useEffect(() => {\n    return () => {\n      if (animationRef.current) {\n        cancelAnimationFrame(animationRef.current);\n      }\n    };\n  }, []);\n\n  // Render component\n  return (\n    <div className=\"w-full p-4 bg-white\">\n      <h2 className=\"text-xl font-bold mb-4 text-center\">Neural Network Learning Visualization (Complex Function)</h2>\n      \n      <div className=\"grid grid-cols-1 md:grid-cols-2 gap-4 mb-4\">\n        <div className=\"bg-gray-50 p-4 rounded\">\n          <h3 className=\"text-lg font-semibold mb-2\">Control Panel</h3>\n          \n          <div className=\"mb-4\">\n            <p className=\"text-sm mb-2\">Network Structure: 1-12-10-8-6-1 (fixed, pyramid architecture)</p>\n            <label className=\"block text-sm font-medium mb-1\">Learning Rate: {learningRate.toFixed(3)}</label>\n            <input\n              type=\"range\"\n              min=\"0.001\"\n              max=\"0.2\"\n              step=\"0.001\"\n              value={learningRate}\n              onChange={e => setLearningRate(parseFloat(e.target.value))}\n              className=\"w-full\"\n              disabled={isTraining}\n            />\n          </div>\n          \n          <div className=\"flex space-x-2\">\n            <button\n              onClick={isTraining ? stopTraining : startTraining}\n              className={`px-4 py-2 rounded ${isTraining ? 'bg-red-500 hover:bg-red-600' : 'bg-green-500 hover:bg-green-600'} text-white font-medium`}\n            >\n              {isTraining ? 'Stop Training' : 'Start Training'}\n            </button>\n            \n            <button\n              onClick={resetNetwork}\n              className=\"px-4 py-2 bg-blue-500 hover:bg-blue-600 text-white font-medium rounded\"\n              disabled={isTraining}\n            >\n              Reset Network\n            </button>\n          </div>\n          \n          <div className=\"mt-4\">\n            <p className=\"text-sm\">Current Epoch: <span className=\"font-semibold\">{epoch}</span></p>\n            <p className=\"text-sm\">Current Loss: <span className=\"font-semibold\">{loss.toFixed(6)}</span></p>\n          </div>\n        </div>\n        \n        <div className=\"bg-gray-50 p-4 rounded\">\n          <h3 className=\"text-lg font-semibold mb-2\">Network Structure Visualization</h3>\n          <div className=\"border rounded bg-white\">\n            <canvas ref={canvasRef} width=\"500\" height=\"300\" className=\"w-full h-64\" />\n          </div>\n          <p className=\"text-xs mt-1 text-gray-500\">Colors represent weights: green for positive, red for negative. Line thickness indicates weight magnitude.</p>\n        </div>\n      </div>\n      \n      <div className=\"bg-gray-50 p-4 rounded\">\n        <h3 className=\"text-lg font-semibold mb-2\">Function Approximation</h3>\n        <div className=\"border rounded bg-white\">\n          <ResponsiveContainer width=\"100%\" height={300}>\n            <LineChart\n              margin={{ top: 20, right: 30, left: 20, bottom: 20 }}\n              data={approximationData}\n            >\n              <CartesianGrid strokeDasharray=\"3 3\" />\n              <XAxis\n                dataKey=\"x\"\n                label={{ value: 'x', position: 'bottom', offset: 0 }}\n                domain={[-Math.PI * 1.1, Math.PI * 1.1]}\n                tickFormatter={(value) => value.toFixed(2)}\n              />\n              <YAxis\n                label={{ value: 'y', angle: -90, position: 'left', offset: -5 }}\n                domain={[-2, 2]}\n              />\n              <Tooltip formatter={(value, name) => [value.toFixed(4), name]} />\n              <Legend />\n              <Line\n                type=\"monotone\"\n                dataKey=\"y\"\n                name=\"Target Function\"\n                stroke=\"#8884d8\"\n                dot={false}\n                strokeWidth={2}\n              />\n              <Line\n                type=\"monotone\"\n                dataKey=\"yApprox\"\n                name=\"Approximation Function\"\n                stroke=\"#82ca9d\"\n                dot={false}\n                strokeWidth={2}\n                isAnimationActive={false}\n              />\n            </LineChart>\n          </ResponsiveContainer>\n        </div>\n        <div className=\"mt-2 text-sm\">\n          <p><span className=\"inline-block w-4 h-2 bg-purple-500 mr-1\"></span> Target Function: sin(x) + 0.5*sin(3x) * x²/5</p>\n          <p><span className=\"inline-block w-4 h-2 bg-green-500 mr-1\"></span> Approximation Function: Current network output</p>\n        </div>\n      </div>\n      \n      <div className=\"mt-4 p-4 bg-gray-50 rounded\">\n        <h3 className=\"text-lg font-semibold mb-2\">Training Data and Backpropagation</h3>\n        <div className=\"grid grid-cols-1 md:grid-cols-2 gap-4\">\n          <div>\n            <h4 className=\"font-medium mb-1\">Training Data Generation</h4>\n            <p className=\"text-sm mb-1\">How training data is created:</p>\n            <ol className=\"text-sm list-decimal list-inside space-y-1\">\n              <li>Sample 50 x values uniformly in range [-π, π]</li>\n              <li>For each x, calculate y = sin(x) as the target</li>\n              <li>These (x, y) pairs form the training dataset</li>\n              <li>During training, samples are randomly selected</li>\n            </ol>\n          </div>\n          <div>\n            <h4 className=\"font-medium mb-1\">Backpropagation Process</h4>\n            <p className=\"text-sm\">\n              Backpropagation is the core learning algorithm for neural networks:\n            </p>\n            <ul className=\"text-sm list-disc list-inside space-y-1\">\n              <li>Green/red connections show weight values and changes</li>\n              <li>Input node displays current sample's x value</li>\n              <li>Output node shows both network output and target value</li>\n              <li>As training progresses, the approximation function (green line) gets closer to the target function (purple line)</li>\n            </ul>\n          </div>\n        </div>\n      </div>\n    </div>\n  );\n};\n\nexport default NeuralNetworkVisualization;\n","import React from 'react';\nimport './App.css';\nimport NeuralNetworkFunctionApproximator from './components/NeuralNetworkFunctionApproximator';\n\nfunction App() {\n  return (\n    <div className=\"App\">\n      <header className=\"App-header\">\n        <h1>Neural Network Function Approximation</h1>\n      </header>\n      <main className=\"App-main\">\n        <NeuralNetworkFunctionApproximator />\n      </main>\n      <footer className=\"App-footer\">\n        <p>Created with React</p>\n      </footer>\n    </div>\n  );\n}\n\nexport default App;\n","const reportWebVitals = onPerfEntry => {\n  if (onPerfEntry && onPerfEntry instanceof Function) {\n    import('web-vitals').then(({ getCLS, getFID, getFCP, getLCP, getTTFB }) => {\n      getCLS(onPerfEntry);\n      getFID(onPerfEntry);\n      getFCP(onPerfEntry);\n      getLCP(onPerfEntry);\n      getTTFB(onPerfEntry);\n    });\n  }\n};\n\nexport default reportWebVitals;\n","import React from 'react';\nimport ReactDOM from 'react-dom/client';\nimport './index.css';\nimport App from './App';\nimport reportWebVitals from './reportWebVitals';\n\nconst root = ReactDOM.createRoot(document.getElementById('root'));\nroot.render(\n  <React.StrictMode>\n    <App />\n  </React.StrictMode>\n);\n\n// If you want to start measuring performance in your app, pass a function\n// to log results (for example: reportWebVitals(console.log))\n// or send to an analytics endpoint. Learn more: https://bit.ly/CRA-vitals\nreportWebVitals();\n"],"sourceRoot":""}